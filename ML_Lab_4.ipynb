{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2FhWM7M4QuSw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "training_size = 100000\n",
        "validation_size = 50000\n",
        "test_size = 50000"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "  return 100*x**3 - 17*x**2 + 3*x + 11"
      ],
      "metadata": {
        "id": "6Z_6lM3GSpZs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Generation:**\n",
        "We generate the data according to the following function:\n",
        "> $f(x) = 100x^3 - 17x^2 + 3x + 11$\n",
        "\n",
        "But in real life, the data don't abide by such a nice polynomial function. There are some noises. Let's say that the noise follows a normal distribution with mean = 0, and standard deviation = 0.1 \n",
        "So, we will generate our data using the following function:\n",
        "> $g(x) = 100x^3 - 17x^2 + 3x + 11 + ϵ $\n",
        "\n",
        "Where, $ϵ \\sim \\mathcal{N}(0, 0.1)$. Let's say, our training data size is $n$. Then we generate $x_{1}, x_{2}, \\cdots, x_{n}$ from a uniform distribution $[0, 1]$. Then for each $x_{i}$, we compute $y_{i} = g(x_{i})$. \n",
        "\n",
        "Now, let our hypothesis be a cubic polynomial of $x$. Hence, $h(x) = ax^3 + bx^2 + cx + d$. From the training dataset, we can create $n$ linear equations with 4 unknowns $(a, b, c, d)$. \n",
        " >$ax_{1}^3 + bx_{1}^2 + cx_{1} + d = y_{1}$\n",
        "\n",
        " > $ax_{2}^3 + bx_{2}^2 + cx_{2} + d = y_{2}$\n",
        "\n",
        " > ...\n",
        "\n",
        " > $ax_{n}^3 + bx_{n}^2 + cx_{n} + d = y_{n}$\n",
        "\n",
        " Notice that this is a system of linear equations. So, we can solve this problem of polynomial regression using just linear regression. And linear regression can be solved using many techniques such as least squares, gradient descent, calculus and so on. The data generation part is shown below."
      ],
      "metadata": {
        "id": "i6Nlw3ZYQ7Uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(a, b, mean, std, size):\n",
        "  x = np.random.uniform(a, b, size)\n",
        "  y = [f(a) for a in x]\n",
        "  noise = np.random.normal(mean, std, size)\n",
        "  y = y + noise\n",
        "  y = np.array(y)\n",
        "  return x, y"
      ],
      "metadata": {
        "id": "8n1ALiDt5GDf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, train_y = generate(0, 1, 0, 0.1, training_size)\n",
        "validation_x, validation_y = generate(0, 1, 0, 0.1, validation_size)\n",
        "test_x, test_y = generate(0, 1, 0, 0.1, test_size)\n",
        "print(train_x)\n",
        "print(train_y)"
      ],
      "metadata": {
        "id": "pryqFsGlRD6A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46f1dec4-4abe-48d1-dfbc-d5f3464235cb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.20093004 0.71121649 0.4852239  ... 0.5260509  0.00817612 0.60059367]\n",
            "[11.85437583 40.50269755 19.85436883 ... 22.34172921 11.17225145\n",
            " 28.33371072]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Regularization and Weight Decay**\n",
        "In linear regression our objective function is the mean square error. We want to minimize that. \n",
        ">> $E = \\frac{\\sum_{i = 1}^{n} (y_{i} - h(x_{i}))^{2}}{n}$\n",
        "\n",
        "But, a complex hypothesis might minimize this empirical error. And we might pick this hypothesis over a simpler one. So, in order to penalize more complex hypothesis we can minimize the following objective function.\n",
        "\n",
        ">> $\\frac{\\sum_{i = 1}^{n} (y_{i} - h(x_{i}))^{2}}{n} + \\alpha$ $c(h)$\n",
        "\n",
        "Where $c(h)$ means the complexity of the hypothesis $h$. There are many ways of defining the complexity of a hypothesis. Two of the most popular ways is to take:\n",
        "\n",
        "$c(h) = |w_{1}|^{2} + |w_{2}|^{2} + \\cdots + |w_{n}|^{2}$, or\n",
        "\n",
        "\n",
        "$c(h) = |w_{1}| + |w_{2}| + \\cdots + |w_{n}|$\n",
        "\n",
        "where $w_{i}$ are the parameters of the hypothesis. If we use the former formula as the complexity, the regression problem is called ridge regression and if we use the second formula, the regression problem is called lasso. This sort fo regularization is called 'weight decay'.\n"
      ],
      "metadata": {
        "id": "bJjYEmeUanAI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Validation**: Our model includes the choice of the degree of the polynomial, coefficients of the polynomial, $\\alpha$ the regularization parameter, $\\lambda$ the learning rate etc. How do we know which combinations of these parameters are going to yield the best result? We cannot rely on the empirical error to decide which model performs the best. Because our models were trained according to the training data. But what if we had access to some spare data? Let's call this the validation data. In that case, we could test our different models in this validation data and choose the best performing data? This process is called validation."
      ],
      "metadata": {
        "id": "_8_WOGPZOHl1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cross Validation**: Sometimes, we do not have access to spare data. So, we need to treat part of our training data as the validation data. Sometimes, the training data is split into $k$ parts. Then we treat each data segment as the validation data and the rest $k-1$ segments are treated as the training data. Then the final validation error is the average of the validation errors in all of these $k$ validation data segments. And finally all of the models go through this k-fold cross validation. The model that performs the best is chosen for the testing phase."
      ],
      "metadata": {
        "id": "MGIlJw1IQvpQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Task**\n",
        "\n",
        "***Part 1:***\n",
        "1.   You have 6 models. \n",
        "> * linear polynomial regressor of degree 4\n",
        "> * linear polynomial regressor of degree 3\n",
        "> * lasso polynomial regressor of degree 4 with $\\alpha$ = 0.01\n",
        "> * lasso polynomial regressor of degree 3 with $\\alpha$ = 0.01\n",
        "> * ridge polynomial regressor of degree 4 with $\\alpha$ = 0.1\n",
        "> * ridge polynomial regressor of degree 3 with $\\alpha$ = 0.1\n",
        "\n",
        "\n",
        "2.   Train on the given training data.\n",
        "3.   Test on the given validation data.\n",
        "4.   Choose the model that performs the best.\n",
        "5.   Test your chosen model on the testing data.\n",
        "***Part 2:***\n",
        "1. Suppose, we don't have the validation data. Use the training data to perform 5-fold validation and then choose the best model.\n",
        "\n"
      ],
      "metadata": {
        "id": "cO7Z33ZGRUV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #########PART-1#########\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "x_2 = []\n",
        "for i in train_x:\n",
        "    x_2.append(i**2)\n",
        "x_2 = np.array(x_2)\n",
        "x_3 = []\n",
        "for i in train_x:\n",
        "    x_3.append(i**3)\n",
        "x_3 = np.array(x_3)\n",
        "ones = []\n",
        "for i in train_x:\n",
        "    ones.append(1)\n",
        "ones = np.array(ones)\n",
        "\n",
        "X3 = np.matrix([x_3,x_2,train_x,ones])\n",
        "X3 = X3.transpose()\n",
        "reg = LinearRegression().fit(X3, train_y)\n",
        "print(reg.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsyb3vg7x-GO",
        "outputId": "4b4ec09e-4b81-4281-b47c-2838e357ff15"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 99.9876187  -16.98375718   2.99315254   0.        ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xsqr = []\n",
        "for i in validation_x:\n",
        "    xsqr.append(i**2)\n",
        "xsqr = np.array(xsqr)\n",
        "xcube = []\n",
        "for i in validation_x:\n",
        "    xcube.append(i**3)\n",
        "xcube = np.array(xcube)\n",
        "ones = []\n",
        "for i in validation_x:\n",
        "    ones.append(1)\n",
        "ones = np.array(ones)\n",
        "\n",
        "validationX3 = np.matrix([xcube,xsqr,validation_x,ones])\n",
        "print(validationX3)\n",
        "\n",
        "validationX3 = validationX3.transpose()\n",
        "\n",
        "print(validationX3)\n",
        "\n",
        "\n",
        "#reg = LinearRegression().fit(validationX, validation_y)\n",
        "\n",
        "prediction = reg.predict(validationX3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mr3pMPHWyv7G",
        "outputId": "94052900-c53d-429b-87f5-0fd8c52f2606"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.78225062 0.17926129 0.43832732 ... 0.13310757 0.44515229 0.02224487]\n",
            " [0.84897964 0.31792475 0.57703084 ... 0.26069648 0.58300518 0.07909577]\n",
            " [0.92140091 0.56384816 0.75962546 ... 0.51058445 0.76354776 0.28123971]\n",
            " [1.         1.         1.         ... 1.         1.         1.        ]]\n",
            "[[0.78225062 0.84897964 0.92140091 1.        ]\n",
            " [0.17926129 0.31792475 0.56384816 1.        ]\n",
            " [0.43832732 0.57703084 0.75962546 1.        ]\n",
            " ...\n",
            " [0.13310757 0.26069648 0.51058445 1.        ]\n",
            " [0.44515229 0.58300518 0.76354776 1.        ]\n",
            " [0.02224487 0.07909577 0.28123971 1.        ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error = (np.sum((validation_y-prediction)**2))/len(validation_y)\n",
        "print(error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6icdvoJ5EXu",
        "outputId": "ff74f188-31ed-41cc-9145-5d67f29df09f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0100394505224592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#######DEGREEE 4\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "x_2 = []\n",
        "for i in train_x:\n",
        "    x_2.append(i**2)\n",
        "x_2 = np.array(x_2)\n",
        "x_3 = []\n",
        "for i in train_x:\n",
        "    x_3.append(i**3)\n",
        "x_3 = np.array(x_3)\n",
        "x_4 = []\n",
        "for i in train_x:\n",
        "    x_4.append(i**4)\n",
        "x_4 = np.array(x_4)\n",
        "ones = []\n",
        "for i in train_x:\n",
        "    ones.append(1)\n",
        "ones = np.array(ones)\n",
        "\n",
        "X4 = np.matrix([x_4,x_3,x_2,train_x,ones])\n",
        "X4 = X4.transpose()\n",
        "reg = LinearRegression().fit(X4, train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQfX_Q6g7dhF",
        "outputId": "d47bc920-8163-457f-ccb7-ba0369297943"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xsqr = []\n",
        "for i in validation_x:\n",
        "    xsqr.append(i**2)\n",
        "xsqr = np.array(xsqr)\n",
        "xcube = []\n",
        "for i in validation_x:\n",
        "    xcube.append(i**3)\n",
        "xcube = np.array(xcube)\n",
        "ones = []\n",
        "xfour = []\n",
        "for i in validation_x:\n",
        "    xfour.append(i**4)\n",
        "xfour = np.array(xfour)\n",
        "for i in validation_x:\n",
        "    ones.append(1)\n",
        "ones = np.array(ones)\n",
        "\n",
        "validationX4 = np.matrix([xfour,xcube,xsqr,validation_x,ones])\n",
        "\n",
        "validationX4 = validationX4.transpose()\n",
        "\n",
        "#reg = LinearRegression().fit(validationX, validation_y)\n",
        "\n",
        "prediction = reg.predict(validationX4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gpGKzSz7-bF",
        "outputId": "ce47683a-ef6f-4c86-bbaa-df8cdcb1affe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error = (sum((validation_y-prediction)**2))/len(validation_y)\n",
        "print(error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4YMnzNj8Z1t",
        "outputId": "9e165433-5ba2-4e35-9b03-a2d01dd992a9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.01003973512829331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(0.010144788182358493>0.010144842913519457)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs8_xVpuGbT_",
        "outputId": "164456b8-6489-4a47-be23-03973d7e8b03"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#######lasso polynomial regressor of degree 4 with α = 0.01\n",
        "from sklearn import linear_model\n",
        "clf = linear_model.Lasso(alpha=0.01)\n",
        "\n",
        "clf.fit(X4,train_y)\n",
        "pred = clf.predict(validationX4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4d8XllE8cat",
        "outputId": "5d2dd767-4270-4d54-8d58-1a506f02c4f4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error = (sum((validation_y-pred)**2))/len(validation_y)\n",
        "print(error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzMAjS34-6Dd",
        "outputId": "0072b34f-8425-464c-c10e-333ef5d11932"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05045280483847748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#######lasso polynomial regressor of degree 3 with α = 0.01\n",
        "from sklearn import linear_model\n",
        "clf = linear_model.Lasso(alpha=0.01)\n",
        "\n",
        "clf.fit(X3,train_y)\n",
        "pred = clf.predict(validationX3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JDIOSG3_azW",
        "outputId": "68174577-b5f1-4365-a9af-b283be887cc7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error = (sum((validation_y-pred)**2))/len(validation_y)\n",
        "print(error)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywCS9hGiAnE_",
        "outputId": "af7909f1-735f-435f-a22d-d67210962cda"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.08532104473042325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#########ridge polynomial regressor of degree 4 with α = 0.1\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "clf = Ridge(alpha=.1)\n",
        "clf.fit(X4, train_y)\n",
        "prediction = clf.predict(validationX4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhWEMfgzApmO",
        "outputId": "784d6617-ceb6-4c91-9ed4-b6f727cc3a02"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error = (sum((validation_y-prediction)**2))/len(validation_y)\n",
        "print(error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFLdXyQQDS7o",
        "outputId": "d42097d2-1be9-4f03-ab29-a2170ca16f65"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.011308480513397183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#########ridge polynomial regressor of degree 3 with α = 0.1\n",
        "\n",
        "clf = Ridge(alpha=.1)\n",
        "clf.fit(X3, train_y)\n",
        "prediction = clf.predict(validationX3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WICCpGxoDkAA",
        "outputId": "f55a052e-455b-4782-c745-3b12b0ae9460"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error = (sum((validation_y-prediction)**2))/len(validation_y)\n",
        "print(error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlOGQZ_jEJzQ",
        "outputId": "492a8012-d413-4f9f-cdb5-70eb412cc922"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.01009264716627077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "train_x,train_y=shuffle(train_x,train_y)\n",
        "\n",
        "lent = len(train_x)\n",
        "(foldsize) = lent//5\n",
        "\n",
        "error = 0.0\n",
        "for i in range(5):\n",
        "    \n",
        "    for j in range(foldsize):\n",
        "        testx = testx.append(train_x[i*foldsize:])\n",
        "        train_x = [x for x in train_x if x not in testx]\n",
        "        testy = testy.append(train_y[i*foldsize:])\n",
        "        train_y = [x for x in train_y if x not in testy]\n",
        "\n",
        "    \n",
        "    x_2 = []\n",
        "    for i in train_x:\n",
        "        x_2.append(i**2)\n",
        "    x_2 = np.array(x_2)\n",
        "    x_3 = []\n",
        "    for i in train_x:\n",
        "        x_3.append(i**3)\n",
        "    x_3 = np.array(x_3)\n",
        "    ones = []\n",
        "    for i in train_x:\n",
        "        ones.append(1)\n",
        "    ones = np.array(ones)\n",
        "\n",
        "    X3 = np.matrix([x_3,x_2,train_x,ones])\n",
        "    X3 = X3.transpose()\n",
        "    model = LinearRegression().fit(X3, train_y)\n",
        "\n",
        "\n",
        "    x_2 = []\n",
        "    for i in testx:\n",
        "        x_2.append(i**2)\n",
        "    x_2 = np.array(x_2)\n",
        "    x_3 = []\n",
        "    for i in testx:\n",
        "        x_3.append(i**3)\n",
        "    x_3 = np.array(x_3)\n",
        "    ones = []\n",
        "    for i in testx:\n",
        "        ones.append(1)\n",
        "    ones = np.array(ones)\n",
        "\n",
        "    Xnew = np.matrix([x_3,x_2,testx,ones])\n",
        "    Xnew = Xnew.transpose()\n",
        "\n",
        "    pred = model.predict(Xnew)\n",
        "    err = sum((testy-pred)**2)/len(testy)\n",
        "    print(err)\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "kRTZwKk0EKwI",
        "outputId": "ec39c398-532d-413b-ea22-a1b36ec385d2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-6dea8de5f9cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfoldsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mtestx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfoldsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_x\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtesty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtesty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfoldsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'testx' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "x_2 = []\n",
        "for i in X_train:\n",
        "    x_2.append(i**2)\n",
        "x_2 = np.array(x_2)\n",
        "x_3 = []\n",
        "for i in X_train:\n",
        "    x_3.append(i**3)\n",
        "x_3 = np.array(x_3)\n",
        "ones = []\n",
        "for i in X_train:\n",
        "    ones.append(1)\n",
        "ones = np.array(ones)\n",
        "\n",
        "X3 = np.matrix([x_3,x_2,X_train,ones])\n",
        "X3 = X3.transpose()\n",
        "model = LinearRegression().fit(X3, y_train)\n",
        "\n",
        "\n",
        "x_2 = []\n",
        "for i in X_test:\n",
        "    x_2.append(i**2)\n",
        "x_2 = np.array(x_2)\n",
        "x_3 = []\n",
        "for i in X_test:\n",
        "    x_3.append(i**3)\n",
        "x_3 = np.array(x_3)\n",
        "ones = []\n",
        "for i in X_test:\n",
        "    ones.append(1)\n",
        "ones = np.array(ones)\n",
        "\n",
        "Xnew = np.matrix([x_3,x_2,X_test,ones])\n",
        "Xnew = Xnew.transpose()\n",
        "\n",
        "pred = model.predict(Xnew)"
      ],
      "metadata": {
        "id": "fzNhl75gFZIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "err = sum((y_test-pred)**2)/len(y_test)\n",
        "print(err)"
      ],
      "metadata": {
        "id": "cUCInr-nH60i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bqG_txmppEot"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}